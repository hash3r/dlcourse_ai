{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666663"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.132736, Train accuracy: 0.206333, val accuracy: 0.218000\n",
      "Loss: 1.706382, Train accuracy: 0.449222, val accuracy: 0.450000\n",
      "Loss: 1.173314, Train accuracy: 0.606000, val accuracy: 0.598000\n",
      "Loss: 0.852998, Train accuracy: 0.631667, val accuracy: 0.624000\n",
      "Loss: 1.109005, Train accuracy: 0.689111, val accuracy: 0.672000\n",
      "Loss: 0.922254, Train accuracy: 0.726778, val accuracy: 0.704000\n",
      "Loss: 1.488328, Train accuracy: 0.736333, val accuracy: 0.695000\n",
      "Loss: 0.881777, Train accuracy: 0.755889, val accuracy: 0.702000\n",
      "Loss: 0.529717, Train accuracy: 0.763556, val accuracy: 0.698000\n",
      "Loss: 1.072395, Train accuracy: 0.780556, val accuracy: 0.717000\n",
      "Loss: 0.466286, Train accuracy: 0.783667, val accuracy: 0.721000\n",
      "Loss: 0.409788, Train accuracy: 0.800444, val accuracy: 0.727000\n",
      "Loss: 0.482072, Train accuracy: 0.819889, val accuracy: 0.732000\n",
      "Loss: 0.551533, Train accuracy: 0.796333, val accuracy: 0.707000\n",
      "Loss: 0.713940, Train accuracy: 0.816667, val accuracy: 0.693000\n",
      "Loss: 0.711819, Train accuracy: 0.782333, val accuracy: 0.699000\n",
      "Loss: 0.382472, Train accuracy: 0.823667, val accuracy: 0.718000\n",
      "Loss: 0.461307, Train accuracy: 0.846111, val accuracy: 0.735000\n",
      "Loss: 0.905866, Train accuracy: 0.846444, val accuracy: 0.728000\n",
      "Loss: 0.960338, Train accuracy: 0.871889, val accuracy: 0.755000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down and train and val accuracy go up for every epoch\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f11ae4ac898>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.328357, Train accuracy: 0.066333, val accuracy: 0.049000\n",
      "Loss: 2.323940, Train accuracy: 0.066333, val accuracy: 0.049000\n",
      "Loss: 2.320913, Train accuracy: 0.066444, val accuracy: 0.049000\n",
      "Loss: 2.317870, Train accuracy: 0.069000, val accuracy: 0.050000\n",
      "Loss: 2.315318, Train accuracy: 0.077333, val accuracy: 0.060000\n",
      "Loss: 2.313394, Train accuracy: 0.089556, val accuracy: 0.071000\n",
      "Loss: 2.311774, Train accuracy: 0.106000, val accuracy: 0.087000\n",
      "Loss: 2.310560, Train accuracy: 0.119667, val accuracy: 0.114000\n",
      "Loss: 2.309264, Train accuracy: 0.135000, val accuracy: 0.128000\n",
      "Loss: 2.308239, Train accuracy: 0.144333, val accuracy: 0.145000\n",
      "Loss: 2.307401, Train accuracy: 0.155000, val accuracy: 0.157000\n",
      "Loss: 2.306052, Train accuracy: 0.164222, val accuracy: 0.169000\n",
      "Loss: 2.306078, Train accuracy: 0.169111, val accuracy: 0.175000\n",
      "Loss: 2.304994, Train accuracy: 0.174889, val accuracy: 0.173000\n",
      "Loss: 2.305572, Train accuracy: 0.179889, val accuracy: 0.180000\n",
      "Loss: 2.304258, Train accuracy: 0.183667, val accuracy: 0.183000\n",
      "Loss: 2.304437, Train accuracy: 0.186333, val accuracy: 0.184000\n",
      "Loss: 2.304577, Train accuracy: 0.188556, val accuracy: 0.190000\n",
      "Loss: 2.304266, Train accuracy: 0.189889, val accuracy: 0.193000\n",
      "Loss: 2.304459, Train accuracy: 0.191667, val accuracy: 0.196000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.995347, Train accuracy: 0.199444, val accuracy: 0.209000\n",
      "Loss: 2.158018, Train accuracy: 0.400889, val accuracy: 0.380000\n",
      "Loss: 1.779726, Train accuracy: 0.569778, val accuracy: 0.546000\n",
      "Loss: 1.194249, Train accuracy: 0.631556, val accuracy: 0.597000\n",
      "Loss: 1.156375, Train accuracy: 0.657444, val accuracy: 0.647000\n",
      "Loss: 1.104781, Train accuracy: 0.700444, val accuracy: 0.679000\n",
      "Loss: 1.330431, Train accuracy: 0.733000, val accuracy: 0.675000\n",
      "Loss: 1.220190, Train accuracy: 0.712889, val accuracy: 0.680000\n",
      "Loss: 0.767778, Train accuracy: 0.737111, val accuracy: 0.690000\n",
      "Loss: 0.625667, Train accuracy: 0.756667, val accuracy: 0.699000\n",
      "Loss: 1.186762, Train accuracy: 0.768556, val accuracy: 0.726000\n",
      "Loss: 1.630323, Train accuracy: 0.772111, val accuracy: 0.693000\n",
      "Loss: 1.041803, Train accuracy: 0.758444, val accuracy: 0.690000\n",
      "Loss: 0.962623, Train accuracy: 0.768556, val accuracy: 0.692000\n",
      "Loss: 1.299693, Train accuracy: 0.803222, val accuracy: 0.730000\n",
      "Loss: 1.055211, Train accuracy: 0.807222, val accuracy: 0.714000\n",
      "Loss: 0.916563, Train accuracy: 0.799000, val accuracy: 0.718000\n",
      "Loss: 0.894073, Train accuracy: 0.772111, val accuracy: 0.718000\n",
      "Loss: 0.815296, Train accuracy: 0.814444, val accuracy: 0.730000\n",
      "Loss: 1.024234, Train accuracy: 0.794222, val accuracy: 0.718000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-4)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=0.95)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.331004, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: 2.327283, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.324905, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.321032, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 2.319592, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 2.311091, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.302504, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.226704, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.059826, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.958393, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.444431, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.892370, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.709634, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.722649, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.381627, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.539125, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.748773, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.710514, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.202204, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.063325, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.977666, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.159844, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.392753, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.448505, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.002897, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.206594, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.663369, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.060343, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.433015, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.806392, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.142241, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.289945, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 2.100367, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.997894, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.723835, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.383973, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.094962, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.783919, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.883621, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.098452, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.761983, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.519063, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.552314, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.313971, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.332430, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.657437, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.917121, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.297976, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.817118, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.134872, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.218824, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.645267, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.636244, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.258910, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.455599, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.579788, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.217248, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.457078, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.600790, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.669229, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.917808, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.465690, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.005962, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.679868, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.280500, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.713962, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.085344, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.762038, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.434318, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.948187, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.322659, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.891033, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.979006, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.357282, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.004316, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.274589, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.252577, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.308162, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.944258, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.597590, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.207257, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.667115, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.187175, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.982105, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 0.938884, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.310287, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.999722, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.388853, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.657266, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 2.145398, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.555274, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.910481, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.995286, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.725586, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.939092, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.566862, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.958960, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.320399, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.253125, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.420438, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.558136, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.255333, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.136512, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.411355, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.197200, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.050762, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.279292, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.653295, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.690725, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.881101, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.846254, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.105455, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.191835, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.280623, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.959778, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.230017, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.513561, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.427216, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.598600, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.212628, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.416603, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.270125, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.153187, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.150011, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.756025, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.161683, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.321944, Train accuracy: 1.000000, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.617141, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.508658, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.439227, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.382313, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.592677, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.210300, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.438965, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.080726, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.348016, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.162155, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.436021, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.257594, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.280948, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.319300, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.266324, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.473630, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.270962, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.362806, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.509459, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.144602, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.367329, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.253612, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.352085, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302569, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.301365, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.289257, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.244211, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.935775, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.649792, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 3.173548, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: 2.289431, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.001192, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.449626, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 0.433407, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.804796, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.506405, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.024663, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.048753, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.004166, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.003657, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.002614, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.001585, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.001874, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-5)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **40%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.946787, Train accuracy: 0.299556, val accuracy: 0.311000\n",
      "Loss: 1.605308, Train accuracy: 0.464444, val accuracy: 0.479000\n",
      "Loss: 1.389214, Train accuracy: 0.522333, val accuracy: 0.534000\n",
      "Loss: 1.436562, Train accuracy: 0.621333, val accuracy: 0.605000\n",
      "Loss: 1.271846, Train accuracy: 0.649667, val accuracy: 0.642000\n",
      "Loss: 1.764709, Train accuracy: 0.555111, val accuracy: 0.549000\n",
      "Loss: 1.097599, Train accuracy: 0.654556, val accuracy: 0.631000\n",
      "Loss: 1.042943, Train accuracy: 0.702667, val accuracy: 0.652000\n",
      "Loss: 0.992914, Train accuracy: 0.719556, val accuracy: 0.657000\n",
      "Loss: 0.726843, Train accuracy: 0.746444, val accuracy: 0.685000\n",
      "Loss: 0.863126, Train accuracy: 0.698333, val accuracy: 0.633000\n",
      "Loss: 1.000663, Train accuracy: 0.702889, val accuracy: 0.627000\n",
      "Loss: 2.108267, Train accuracy: 0.645444, val accuracy: 0.575000\n",
      "Loss: 0.952099, Train accuracy: 0.750778, val accuracy: 0.671000\n",
      "Loss: 1.174171, Train accuracy: 0.713000, val accuracy: 0.645000\n",
      "Loss: 0.746591, Train accuracy: 0.756444, val accuracy: 0.695000\n",
      "Loss: 0.554886, Train accuracy: 0.816889, val accuracy: 0.723000\n",
      "Loss: 0.640105, Train accuracy: 0.794889, val accuracy: 0.679000\n",
      "Loss: 1.866583, Train accuracy: 0.740556, val accuracy: 0.633000\n",
      "Loss: 0.622634, Train accuracy: 0.770667, val accuracy: 0.674000\n",
      "Loss: 0.635650, Train accuracy: 0.828556, val accuracy: 0.724000\n",
      "Loss: 0.514464, Train accuracy: 0.844444, val accuracy: 0.724000\n",
      "Loss: 0.645221, Train accuracy: 0.827889, val accuracy: 0.710000\n",
      "Loss: 0.695726, Train accuracy: 0.789000, val accuracy: 0.683000\n",
      "Loss: 0.943858, Train accuracy: 0.790778, val accuracy: 0.676000\n",
      "Loss: 0.678179, Train accuracy: 0.836556, val accuracy: 0.712000\n",
      "Loss: 1.147650, Train accuracy: 0.805444, val accuracy: 0.694000\n",
      "Loss: 0.372392, Train accuracy: 0.864222, val accuracy: 0.722000\n",
      "Loss: 0.931701, Train accuracy: 0.782222, val accuracy: 0.677000\n",
      "Loss: 1.051512, Train accuracy: 0.845333, val accuracy: 0.712000\n",
      "Loss: 0.972086, Train accuracy: 0.860000, val accuracy: 0.719000\n",
      "Loss: 0.665567, Train accuracy: 0.825667, val accuracy: 0.681000\n",
      "Loss: 0.748077, Train accuracy: 0.866889, val accuracy: 0.713000\n",
      "Loss: 0.712486, Train accuracy: 0.785111, val accuracy: 0.653000\n",
      "Loss: 0.719944, Train accuracy: 0.891333, val accuracy: 0.741000\n",
      "Loss: 0.502502, Train accuracy: 0.879667, val accuracy: 0.737000\n",
      "Loss: 0.797702, Train accuracy: 0.823222, val accuracy: 0.677000\n",
      "Loss: 0.747473, Train accuracy: 0.845333, val accuracy: 0.700000\n",
      "Loss: 0.876087, Train accuracy: 0.812556, val accuracy: 0.670000\n",
      "Loss: 0.827302, Train accuracy: 0.776667, val accuracy: 0.652000\n",
      "Loss: 2.105407, Train accuracy: 0.749111, val accuracy: 0.652000\n",
      "Loss: 0.899700, Train accuracy: 0.799556, val accuracy: 0.668000\n",
      "Loss: 0.687985, Train accuracy: 0.852889, val accuracy: 0.712000\n",
      "Loss: 1.049750, Train accuracy: 0.814444, val accuracy: 0.672000\n",
      "Loss: 0.698485, Train accuracy: 0.890778, val accuracy: 0.726000\n",
      "Loss: 0.608809, Train accuracy: 0.875111, val accuracy: 0.724000\n",
      "Loss: 0.699853, Train accuracy: 0.850667, val accuracy: 0.727000\n",
      "Loss: 0.580860, Train accuracy: 0.900889, val accuracy: 0.749000\n",
      "Loss: 0.439953, Train accuracy: 0.888000, val accuracy: 0.726000\n",
      "Loss: 0.691435, Train accuracy: 0.894444, val accuracy: 0.733000\n",
      "Loss: 0.548628, Train accuracy: 0.908556, val accuracy: 0.747000\n",
      "Loss: 0.978658, Train accuracy: 0.828889, val accuracy: 0.699000\n",
      "Loss: 0.627139, Train accuracy: 0.858778, val accuracy: 0.718000\n",
      "Loss: 0.771336, Train accuracy: 0.812444, val accuracy: 0.668000\n",
      "Loss: 0.475352, Train accuracy: 0.940889, val accuracy: 0.749000\n",
      "Loss: 0.657441, Train accuracy: 0.842111, val accuracy: 0.690000\n",
      "Loss: 0.651690, Train accuracy: 0.870333, val accuracy: 0.717000\n",
      "Loss: 0.530533, Train accuracy: 0.932333, val accuracy: 0.761000\n",
      "Loss: 0.712712, Train accuracy: 0.909333, val accuracy: 0.754000\n",
      "Loss: 1.881086, Train accuracy: 0.782667, val accuracy: 0.649000\n",
      "Loss: 0.662027, Train accuracy: 0.867000, val accuracy: 0.709000\n",
      "Loss: 0.665382, Train accuracy: 0.872889, val accuracy: 0.712000\n",
      "Loss: 0.859265, Train accuracy: 0.816222, val accuracy: 0.701000\n",
      "Loss: 0.583048, Train accuracy: 0.873444, val accuracy: 0.707000\n",
      "Loss: 0.386098, Train accuracy: 0.934889, val accuracy: 0.741000\n",
      "Loss: 1.318036, Train accuracy: 0.719000, val accuracy: 0.625000\n",
      "Loss: 0.564951, Train accuracy: 0.912889, val accuracy: 0.734000\n",
      "Loss: 0.773780, Train accuracy: 0.921667, val accuracy: 0.753000\n",
      "Loss: 0.715274, Train accuracy: 0.905667, val accuracy: 0.730000\n",
      "Loss: 0.626156, Train accuracy: 0.779222, val accuracy: 0.661000\n",
      "Loss: 0.658475, Train accuracy: 0.919889, val accuracy: 0.747000\n",
      "Loss: 1.096854, Train accuracy: 0.738889, val accuracy: 0.604000\n",
      "Loss: 0.608703, Train accuracy: 0.919444, val accuracy: 0.738000\n",
      "Loss: 0.444311, Train accuracy: 0.925333, val accuracy: 0.745000\n",
      "Loss: 0.482845, Train accuracy: 0.940556, val accuracy: 0.755000\n",
      "Loss: 0.644661, Train accuracy: 0.926778, val accuracy: 0.749000\n",
      "Loss: 0.506533, Train accuracy: 0.923667, val accuracy: 0.743000\n",
      "Loss: 0.495152, Train accuracy: 0.909889, val accuracy: 0.731000\n",
      "Loss: 0.572786, Train accuracy: 0.903556, val accuracy: 0.728000\n",
      "Loss: 0.423039, Train accuracy: 0.936000, val accuracy: 0.749000\n",
      "Loss: 0.517408, Train accuracy: 0.892111, val accuracy: 0.719000\n",
      "Loss: 0.626554, Train accuracy: 0.907444, val accuracy: 0.731000\n",
      "Loss: 0.387800, Train accuracy: 0.909556, val accuracy: 0.736000\n",
      "Loss: 0.433724, Train accuracy: 0.955000, val accuracy: 0.759000\n",
      "Loss: 0.802884, Train accuracy: 0.897000, val accuracy: 0.736000\n",
      "Loss: 0.667305, Train accuracy: 0.899000, val accuracy: 0.736000\n",
      "Loss: 0.527176, Train accuracy: 0.892222, val accuracy: 0.732000\n",
      "Loss: 1.227471, Train accuracy: 0.764222, val accuracy: 0.631000\n",
      "Loss: 0.450020, Train accuracy: 0.942222, val accuracy: 0.753000\n",
      "Loss: 0.440488, Train accuracy: 0.935222, val accuracy: 0.748000\n",
      "Loss: 0.576142, Train accuracy: 0.883667, val accuracy: 0.716000\n",
      "Loss: 0.577083, Train accuracy: 0.880778, val accuracy: 0.703000\n",
      "Loss: 0.522309, Train accuracy: 0.913444, val accuracy: 0.718000\n",
      "Loss: 4.815813, Train accuracy: 0.551000, val accuracy: 0.515000\n",
      "Loss: 0.666564, Train accuracy: 0.942667, val accuracy: 0.759000\n",
      "Loss: 0.405861, Train accuracy: 0.947000, val accuracy: 0.759000\n",
      "Loss: 0.424521, Train accuracy: 0.931222, val accuracy: 0.757000\n",
      "Loss: 0.839654, Train accuracy: 0.808444, val accuracy: 0.668000\n",
      "Loss: 0.676248, Train accuracy: 0.897111, val accuracy: 0.726000\n",
      "Loss: 0.624901, Train accuracy: 0.879889, val accuracy: 0.717000\n",
      "Loss: 0.446202, Train accuracy: 0.946222, val accuracy: 0.755000\n",
      "Loss: 0.481162, Train accuracy: 0.853444, val accuracy: 0.722000\n",
      "Loss: 0.405159, Train accuracy: 0.956667, val accuracy: 0.762000\n",
      "Loss: 1.199280, Train accuracy: 0.720111, val accuracy: 0.599000\n",
      "Loss: 0.522824, Train accuracy: 0.935556, val accuracy: 0.747000\n",
      "Loss: 0.416152, Train accuracy: 0.949889, val accuracy: 0.759000\n",
      "Loss: 0.720932, Train accuracy: 0.882000, val accuracy: 0.701000\n",
      "Loss: 0.410644, Train accuracy: 0.937444, val accuracy: 0.754000\n",
      "Loss: 0.785071, Train accuracy: 0.860667, val accuracy: 0.679000\n",
      "Loss: 0.539798, Train accuracy: 0.920222, val accuracy: 0.732000\n",
      "Loss: 2.353510, Train accuracy: 0.718556, val accuracy: 0.582000\n",
      "Loss: 0.716922, Train accuracy: 0.929667, val accuracy: 0.739000\n",
      "Loss: 1.790555, Train accuracy: 0.782556, val accuracy: 0.664000\n",
      "Loss: 1.016637, Train accuracy: 0.883333, val accuracy: 0.706000\n",
      "Loss: 0.622743, Train accuracy: 0.876556, val accuracy: 0.717000\n",
      "Loss: 0.431688, Train accuracy: 0.955000, val accuracy: 0.760000\n",
      "Loss: 0.541886, Train accuracy: 0.913333, val accuracy: 0.722000\n",
      "Loss: 0.433768, Train accuracy: 0.915889, val accuracy: 0.724000\n",
      "Loss: 1.388196, Train accuracy: 0.784222, val accuracy: 0.647000\n",
      "Loss: 0.503812, Train accuracy: 0.912667, val accuracy: 0.723000\n",
      "Loss: 0.566201, Train accuracy: 0.913222, val accuracy: 0.719000\n",
      "Loss: 0.430560, Train accuracy: 0.926444, val accuracy: 0.737000\n",
      "Loss: 0.523892, Train accuracy: 0.905778, val accuracy: 0.722000\n",
      "Loss: 0.448486, Train accuracy: 0.948667, val accuracy: 0.743000\n",
      "Loss: 1.095686, Train accuracy: 0.838444, val accuracy: 0.690000\n",
      "Loss: 0.632598, Train accuracy: 0.894111, val accuracy: 0.738000\n",
      "Loss: 0.389718, Train accuracy: 0.919222, val accuracy: 0.737000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.624257, Train accuracy: 0.900889, val accuracy: 0.729000\n",
      "Loss: 0.319418, Train accuracy: 0.969111, val accuracy: 0.759000\n",
      "Loss: 0.732257, Train accuracy: 0.870444, val accuracy: 0.707000\n",
      "Loss: 0.617563, Train accuracy: 0.944000, val accuracy: 0.744000\n",
      "Loss: 0.404615, Train accuracy: 0.909111, val accuracy: 0.732000\n",
      "Loss: 0.745926, Train accuracy: 0.792778, val accuracy: 0.651000\n",
      "Loss: 0.399751, Train accuracy: 0.965000, val accuracy: 0.764000\n",
      "Loss: 0.875631, Train accuracy: 0.713556, val accuracy: 0.597000\n",
      "Loss: 0.514146, Train accuracy: 0.939111, val accuracy: 0.744000\n",
      "Loss: 0.536882, Train accuracy: 0.930778, val accuracy: 0.739000\n",
      "Loss: 0.458258, Train accuracy: 0.951889, val accuracy: 0.754000\n",
      "Loss: 0.623992, Train accuracy: 0.911444, val accuracy: 0.733000\n",
      "Loss: 0.881651, Train accuracy: 0.906000, val accuracy: 0.729000\n",
      "Loss: 0.676700, Train accuracy: 0.926889, val accuracy: 0.737000\n",
      "Loss: 0.483363, Train accuracy: 0.960000, val accuracy: 0.766000\n",
      "Loss: 0.670962, Train accuracy: 0.879889, val accuracy: 0.707000\n",
      "Loss: 0.504791, Train accuracy: 0.859667, val accuracy: 0.693000\n",
      "Loss: 1.153133, Train accuracy: 0.820444, val accuracy: 0.664000\n",
      "Loss: 0.407105, Train accuracy: 0.951222, val accuracy: 0.745000\n",
      "Loss: 1.277238, Train accuracy: 0.752778, val accuracy: 0.636000\n",
      "Loss: 0.357916, Train accuracy: 0.963222, val accuracy: 0.766000\n",
      "Loss: 0.414092, Train accuracy: 0.964444, val accuracy: 0.757000\n",
      "Loss: 0.591082, Train accuracy: 0.916667, val accuracy: 0.734000\n",
      "Loss: 0.501918, Train accuracy: 0.971667, val accuracy: 0.776000\n",
      "Loss: 0.669423, Train accuracy: 0.868556, val accuracy: 0.710000\n",
      "Loss: 0.497741, Train accuracy: 0.926111, val accuracy: 0.749000\n",
      "Loss: 1.032350, Train accuracy: 0.791667, val accuracy: 0.642000\n",
      "Loss: 1.309730, Train accuracy: 0.781778, val accuracy: 0.655000\n",
      "Loss: 0.489529, Train accuracy: 0.945556, val accuracy: 0.758000\n",
      "Loss: 0.547485, Train accuracy: 0.903889, val accuracy: 0.726000\n",
      "Loss: 0.725822, Train accuracy: 0.866333, val accuracy: 0.708000\n",
      "Loss: 0.419385, Train accuracy: 0.963667, val accuracy: 0.757000\n",
      "Loss: 0.367635, Train accuracy: 0.963111, val accuracy: 0.757000\n",
      "Loss: 3.363393, Train accuracy: 0.592222, val accuracy: 0.516000\n",
      "Loss: 1.272985, Train accuracy: 0.776444, val accuracy: 0.651000\n",
      "Loss: 0.481810, Train accuracy: 0.942000, val accuracy: 0.749000\n",
      "Loss: 0.755152, Train accuracy: 0.903000, val accuracy: 0.723000\n",
      "Loss: 0.458208, Train accuracy: 0.951333, val accuracy: 0.750000\n",
      "Loss: 0.816708, Train accuracy: 0.816000, val accuracy: 0.664000\n",
      "Loss: 0.461830, Train accuracy: 0.943333, val accuracy: 0.757000\n",
      "Loss: 0.561284, Train accuracy: 0.912778, val accuracy: 0.732000\n",
      "Loss: 0.541596, Train accuracy: 0.950111, val accuracy: 0.756000\n",
      "Loss: 0.528091, Train accuracy: 0.953111, val accuracy: 0.748000\n",
      "Loss: 0.426957, Train accuracy: 0.940889, val accuracy: 0.753000\n",
      "Loss: 0.434037, Train accuracy: 0.965111, val accuracy: 0.758000\n",
      "Loss: 0.829446, Train accuracy: 0.772889, val accuracy: 0.638000\n",
      "Loss: 0.502039, Train accuracy: 0.932000, val accuracy: 0.742000\n",
      "Loss: 0.548083, Train accuracy: 0.952000, val accuracy: 0.747000\n",
      "Loss: 1.083525, Train accuracy: 0.815333, val accuracy: 0.666000\n",
      "Loss: 0.439879, Train accuracy: 0.947333, val accuracy: 0.742000\n",
      "Loss: 0.646373, Train accuracy: 0.912667, val accuracy: 0.737000\n",
      "Loss: 0.906220, Train accuracy: 0.829111, val accuracy: 0.690000\n",
      "Loss: 0.561333, Train accuracy: 0.903222, val accuracy: 0.716000\n",
      "Loss: 0.849866, Train accuracy: 0.861778, val accuracy: 0.694000\n",
      "Loss: 0.477440, Train accuracy: 0.946778, val accuracy: 0.749000\n",
      "Loss: 2.288634, Train accuracy: 0.700444, val accuracy: 0.596000\n",
      "Loss: 0.517280, Train accuracy: 0.951778, val accuracy: 0.752000\n",
      "Loss: 0.677876, Train accuracy: 0.858556, val accuracy: 0.715000\n",
      "Loss: 0.545059, Train accuracy: 0.946333, val accuracy: 0.762000\n",
      "Loss: 0.446099, Train accuracy: 0.957778, val accuracy: 0.771000\n",
      "Loss: 0.819349, Train accuracy: 0.747333, val accuracy: 0.613000\n",
      "Loss: 0.628452, Train accuracy: 0.924000, val accuracy: 0.735000\n",
      "Loss: 0.480149, Train accuracy: 0.962000, val accuracy: 0.764000\n",
      "Loss: 1.249957, Train accuracy: 0.728889, val accuracy: 0.603000\n",
      "Loss: 0.428188, Train accuracy: 0.944111, val accuracy: 0.739000\n",
      "Loss: 0.495127, Train accuracy: 0.948444, val accuracy: 0.750000\n",
      "Loss: 0.490904, Train accuracy: 0.929222, val accuracy: 0.741000\n",
      "Loss: 0.444341, Train accuracy: 0.965889, val accuracy: 0.762000\n",
      "Loss: 0.531380, Train accuracy: 0.929000, val accuracy: 0.754000\n",
      "Loss: 0.662221, Train accuracy: 0.925667, val accuracy: 0.748000\n",
      "Loss: 0.823787, Train accuracy: 0.789667, val accuracy: 0.652000\n",
      "Loss: 0.562168, Train accuracy: 0.934000, val accuracy: 0.736000\n",
      "Loss: 0.505991, Train accuracy: 0.894222, val accuracy: 0.722000\n",
      "0.5 0.0001 0.8 0.722\n",
      "Loss: 1.681869, Train accuracy: 0.329667, val accuracy: 0.327000\n",
      "Loss: 2.146473, Train accuracy: 0.363111, val accuracy: 0.381000\n",
      "Loss: 1.577088, Train accuracy: 0.592889, val accuracy: 0.583000\n",
      "Loss: 0.953740, Train accuracy: 0.642111, val accuracy: 0.644000\n",
      "Loss: 1.260923, Train accuracy: 0.597889, val accuracy: 0.581000\n",
      "Loss: 1.000236, Train accuracy: 0.599667, val accuracy: 0.587000\n",
      "Loss: 1.369287, Train accuracy: 0.614444, val accuracy: 0.574000\n",
      "Loss: 1.145630, Train accuracy: 0.606667, val accuracy: 0.572000\n",
      "Loss: 1.125276, Train accuracy: 0.724444, val accuracy: 0.676000\n",
      "Loss: 1.314943, Train accuracy: 0.625111, val accuracy: 0.600000\n",
      "Loss: 0.870526, Train accuracy: 0.727889, val accuracy: 0.668000\n",
      "Loss: 0.938206, Train accuracy: 0.781778, val accuracy: 0.680000\n",
      "Loss: 1.485140, Train accuracy: 0.688222, val accuracy: 0.632000\n",
      "Loss: 0.615092, Train accuracy: 0.797000, val accuracy: 0.702000\n",
      "Loss: 1.013448, Train accuracy: 0.724889, val accuracy: 0.648000\n",
      "Loss: 0.930361, Train accuracy: 0.750556, val accuracy: 0.667000\n",
      "Loss: 0.855822, Train accuracy: 0.766000, val accuracy: 0.686000\n",
      "Loss: 0.794118, Train accuracy: 0.760667, val accuracy: 0.655000\n",
      "Loss: 0.679329, Train accuracy: 0.823333, val accuracy: 0.701000\n",
      "Loss: 1.432208, Train accuracy: 0.731667, val accuracy: 0.655000\n",
      "Loss: 1.711818, Train accuracy: 0.738889, val accuracy: 0.649000\n",
      "Loss: 0.603042, Train accuracy: 0.848000, val accuracy: 0.702000\n",
      "Loss: 0.794440, Train accuracy: 0.749778, val accuracy: 0.655000\n",
      "Loss: 0.577788, Train accuracy: 0.851556, val accuracy: 0.713000\n",
      "Loss: 0.680336, Train accuracy: 0.853889, val accuracy: 0.719000\n",
      "Loss: 0.565336, Train accuracy: 0.875111, val accuracy: 0.739000\n",
      "Loss: 0.685936, Train accuracy: 0.775333, val accuracy: 0.646000\n",
      "Loss: 0.622958, Train accuracy: 0.845889, val accuracy: 0.718000\n",
      "Loss: 1.223762, Train accuracy: 0.718000, val accuracy: 0.614000\n",
      "Loss: 0.712613, Train accuracy: 0.883111, val accuracy: 0.737000\n",
      "Loss: 0.678993, Train accuracy: 0.867444, val accuracy: 0.725000\n",
      "Loss: 0.557706, Train accuracy: 0.892444, val accuracy: 0.729000\n",
      "Loss: 0.395316, Train accuracy: 0.881667, val accuracy: 0.717000\n",
      "Loss: 0.561739, Train accuracy: 0.789333, val accuracy: 0.667000\n",
      "Loss: 0.679101, Train accuracy: 0.820778, val accuracy: 0.699000\n",
      "Loss: 1.250396, Train accuracy: 0.768444, val accuracy: 0.640000\n",
      "Loss: 0.680590, Train accuracy: 0.868889, val accuracy: 0.696000\n",
      "Loss: 0.904318, Train accuracy: 0.847000, val accuracy: 0.701000\n",
      "Loss: 3.918541, Train accuracy: 0.643222, val accuracy: 0.540000\n",
      "Loss: 0.827744, Train accuracy: 0.845222, val accuracy: 0.691000\n",
      "Loss: 0.486237, Train accuracy: 0.902111, val accuracy: 0.746000\n",
      "Loss: 0.848546, Train accuracy: 0.768889, val accuracy: 0.637000\n",
      "Loss: 0.621387, Train accuracy: 0.887444, val accuracy: 0.734000\n",
      "Loss: 0.856529, Train accuracy: 0.852333, val accuracy: 0.699000\n",
      "Loss: 0.474639, Train accuracy: 0.818889, val accuracy: 0.687000\n",
      "Loss: 0.570178, Train accuracy: 0.878333, val accuracy: 0.711000\n",
      "Loss: 0.595366, Train accuracy: 0.893778, val accuracy: 0.721000\n",
      "Loss: 0.498659, Train accuracy: 0.893111, val accuracy: 0.721000\n",
      "Loss: 1.677336, Train accuracy: 0.686111, val accuracy: 0.608000\n",
      "Loss: 0.393209, Train accuracy: 0.900778, val accuracy: 0.733000\n",
      "Loss: 0.565117, Train accuracy: 0.924000, val accuracy: 0.751000\n",
      "Loss: 1.249276, Train accuracy: 0.843333, val accuracy: 0.691000\n",
      "Loss: 0.794881, Train accuracy: 0.842889, val accuracy: 0.690000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.779204, Train accuracy: 0.831889, val accuracy: 0.702000\n",
      "Loss: 0.753147, Train accuracy: 0.847444, val accuracy: 0.699000\n",
      "Loss: 0.430802, Train accuracy: 0.866556, val accuracy: 0.692000\n",
      "Loss: 0.527979, Train accuracy: 0.881000, val accuracy: 0.710000\n",
      "Loss: 0.440435, Train accuracy: 0.910333, val accuracy: 0.722000\n",
      "Loss: 1.267381, Train accuracy: 0.700778, val accuracy: 0.599000\n",
      "Loss: 0.480001, Train accuracy: 0.912778, val accuracy: 0.731000\n",
      "Loss: 0.817574, Train accuracy: 0.864222, val accuracy: 0.699000\n",
      "Loss: 0.406651, Train accuracy: 0.912444, val accuracy: 0.736000\n",
      "Loss: 0.602086, Train accuracy: 0.892889, val accuracy: 0.716000\n",
      "Loss: 0.418264, Train accuracy: 0.931111, val accuracy: 0.755000\n",
      "Loss: 0.547932, Train accuracy: 0.924222, val accuracy: 0.732000\n",
      "Loss: 1.226439, Train accuracy: 0.797444, val accuracy: 0.668000\n",
      "Loss: 0.811141, Train accuracy: 0.874778, val accuracy: 0.726000\n",
      "Loss: 0.902697, Train accuracy: 0.906444, val accuracy: 0.732000\n",
      "Loss: 0.942393, Train accuracy: 0.807000, val accuracy: 0.667000\n",
      "Loss: 0.477150, Train accuracy: 0.929556, val accuracy: 0.742000\n",
      "Loss: 0.747204, Train accuracy: 0.833444, val accuracy: 0.690000\n",
      "Loss: 0.423365, Train accuracy: 0.945111, val accuracy: 0.757000\n",
      "Loss: 6.235184, Train accuracy: 0.623333, val accuracy: 0.536000\n",
      "Loss: 0.406688, Train accuracy: 0.925333, val accuracy: 0.755000\n",
      "Loss: 0.542558, Train accuracy: 0.921000, val accuracy: 0.737000\n",
      "Loss: 0.546225, Train accuracy: 0.926444, val accuracy: 0.723000\n",
      "Loss: 0.715961, Train accuracy: 0.848000, val accuracy: 0.682000\n",
      "Loss: 0.573227, Train accuracy: 0.935333, val accuracy: 0.746000\n",
      "Loss: 0.742179, Train accuracy: 0.812778, val accuracy: 0.670000\n",
      "Loss: 0.580331, Train accuracy: 0.908556, val accuracy: 0.711000\n",
      "Loss: 0.471111, Train accuracy: 0.937556, val accuracy: 0.725000\n",
      "Loss: 0.570286, Train accuracy: 0.856556, val accuracy: 0.692000\n",
      "Loss: 0.422557, Train accuracy: 0.947222, val accuracy: 0.744000\n",
      "Loss: 0.693985, Train accuracy: 0.899444, val accuracy: 0.723000\n",
      "Loss: 0.625247, Train accuracy: 0.901778, val accuracy: 0.720000\n",
      "Loss: 0.501485, Train accuracy: 0.951556, val accuracy: 0.746000\n",
      "Loss: 0.674723, Train accuracy: 0.870222, val accuracy: 0.692000\n",
      "Loss: 0.474987, Train accuracy: 0.952222, val accuracy: 0.745000\n",
      "Loss: 0.651551, Train accuracy: 0.913889, val accuracy: 0.721000\n",
      "Loss: 0.508301, Train accuracy: 0.916111, val accuracy: 0.711000\n",
      "Loss: 1.845972, Train accuracy: 0.746556, val accuracy: 0.603000\n",
      "Loss: 0.460809, Train accuracy: 0.953222, val accuracy: 0.765000\n",
      "Loss: 0.744422, Train accuracy: 0.904889, val accuracy: 0.724000\n",
      "Loss: 0.687230, Train accuracy: 0.867333, val accuracy: 0.680000\n",
      "Loss: 0.389477, Train accuracy: 0.957444, val accuracy: 0.745000\n",
      "Loss: 0.832786, Train accuracy: 0.878111, val accuracy: 0.701000\n",
      "Loss: 1.097564, Train accuracy: 0.781111, val accuracy: 0.636000\n",
      "Loss: 0.383388, Train accuracy: 0.928000, val accuracy: 0.762000\n",
      "Loss: 0.505062, Train accuracy: 0.930000, val accuracy: 0.737000\n",
      "Loss: 0.531470, Train accuracy: 0.925222, val accuracy: 0.741000\n",
      "Loss: 1.245724, Train accuracy: 0.773000, val accuracy: 0.648000\n",
      "Loss: 0.834737, Train accuracy: 0.837333, val accuracy: 0.677000\n",
      "Loss: 0.651500, Train accuracy: 0.882889, val accuracy: 0.705000\n",
      "Loss: 1.110545, Train accuracy: 0.783333, val accuracy: 0.642000\n",
      "Loss: 0.407264, Train accuracy: 0.930556, val accuracy: 0.735000\n",
      "Loss: 4.636023, Train accuracy: 0.685111, val accuracy: 0.566000\n",
      "Loss: 0.502142, Train accuracy: 0.926111, val accuracy: 0.714000\n",
      "Loss: 0.385909, Train accuracy: 0.919444, val accuracy: 0.735000\n",
      "Loss: 0.546193, Train accuracy: 0.923667, val accuracy: 0.739000\n",
      "Loss: 0.359585, Train accuracy: 0.965889, val accuracy: 0.752000\n",
      "Loss: 0.551608, Train accuracy: 0.887333, val accuracy: 0.706000\n",
      "Loss: 4.442067, Train accuracy: 0.502444, val accuracy: 0.445000\n",
      "Loss: 0.370488, Train accuracy: 0.961889, val accuracy: 0.756000\n",
      "Loss: 0.873221, Train accuracy: 0.895667, val accuracy: 0.726000\n",
      "Loss: 0.498570, Train accuracy: 0.963889, val accuracy: 0.752000\n",
      "Loss: 0.584725, Train accuracy: 0.905778, val accuracy: 0.711000\n",
      "Loss: 0.453506, Train accuracy: 0.953333, val accuracy: 0.748000\n",
      "Loss: 0.429087, Train accuracy: 0.921111, val accuracy: 0.716000\n",
      "Loss: 0.529096, Train accuracy: 0.874444, val accuracy: 0.698000\n",
      "Loss: 0.633539, Train accuracy: 0.905889, val accuracy: 0.738000\n",
      "Loss: 0.416931, Train accuracy: 0.862444, val accuracy: 0.698000\n",
      "Loss: 0.446274, Train accuracy: 0.929111, val accuracy: 0.737000\n",
      "Loss: 0.612855, Train accuracy: 0.922556, val accuracy: 0.729000\n",
      "Loss: 0.605769, Train accuracy: 0.948889, val accuracy: 0.751000\n",
      "Loss: 0.742155, Train accuracy: 0.788222, val accuracy: 0.638000\n",
      "Loss: 1.421460, Train accuracy: 0.710667, val accuracy: 0.597000\n",
      "Loss: 0.444417, Train accuracy: 0.960778, val accuracy: 0.748000\n",
      "Loss: 0.589606, Train accuracy: 0.944333, val accuracy: 0.737000\n",
      "Loss: 0.429822, Train accuracy: 0.921000, val accuracy: 0.723000\n",
      "Loss: 0.663651, Train accuracy: 0.886333, val accuracy: 0.709000\n",
      "Loss: 0.381084, Train accuracy: 0.946778, val accuracy: 0.746000\n",
      "Loss: 0.705869, Train accuracy: 0.857444, val accuracy: 0.706000\n",
      "Loss: 0.619187, Train accuracy: 0.931444, val accuracy: 0.731000\n",
      "Loss: 0.419547, Train accuracy: 0.866889, val accuracy: 0.700000\n",
      "Loss: 0.492130, Train accuracy: 0.941444, val accuracy: 0.749000\n",
      "Loss: 3.508039, Train accuracy: 0.593333, val accuracy: 0.523000\n",
      "Loss: 0.623900, Train accuracy: 0.937889, val accuracy: 0.741000\n",
      "Loss: 0.552558, Train accuracy: 0.946333, val accuracy: 0.737000\n",
      "Loss: 5.201278, Train accuracy: 0.402444, val accuracy: 0.393000\n",
      "Loss: 0.532447, Train accuracy: 0.934889, val accuracy: 0.742000\n",
      "Loss: 0.710036, Train accuracy: 0.944333, val accuracy: 0.731000\n",
      "Loss: 0.529156, Train accuracy: 0.872333, val accuracy: 0.695000\n",
      "Loss: 0.518257, Train accuracy: 0.954111, val accuracy: 0.760000\n",
      "Loss: 0.412814, Train accuracy: 0.969889, val accuracy: 0.756000\n",
      "Loss: 0.661602, Train accuracy: 0.868444, val accuracy: 0.686000\n",
      "Loss: 0.519268, Train accuracy: 0.941111, val accuracy: 0.735000\n",
      "Loss: 0.405504, Train accuracy: 0.958556, val accuracy: 0.767000\n",
      "Loss: 0.511867, Train accuracy: 0.902000, val accuracy: 0.720000\n",
      "Loss: 0.958073, Train accuracy: 0.877444, val accuracy: 0.712000\n",
      "Loss: 0.966884, Train accuracy: 0.858444, val accuracy: 0.700000\n",
      "Loss: 0.405856, Train accuracy: 0.973111, val accuracy: 0.771000\n",
      "Loss: 1.864148, Train accuracy: 0.688444, val accuracy: 0.571000\n",
      "Loss: 0.498114, Train accuracy: 0.930889, val accuracy: 0.719000\n",
      "Loss: 0.462999, Train accuracy: 0.969778, val accuracy: 0.760000\n",
      "Loss: 0.543686, Train accuracy: 0.946889, val accuracy: 0.731000\n",
      "Loss: 0.460871, Train accuracy: 0.956333, val accuracy: 0.750000\n",
      "Loss: 0.503681, Train accuracy: 0.908889, val accuracy: 0.718000\n",
      "Loss: 0.581918, Train accuracy: 0.952778, val accuracy: 0.745000\n",
      "Loss: 0.521542, Train accuracy: 0.921000, val accuracy: 0.718000\n",
      "Loss: 0.804134, Train accuracy: 0.850222, val accuracy: 0.681000\n",
      "Loss: 0.830591, Train accuracy: 0.892889, val accuracy: 0.701000\n",
      "Loss: 3.138686, Train accuracy: 0.743667, val accuracy: 0.629000\n",
      "Loss: 0.556882, Train accuracy: 0.936667, val accuracy: 0.738000\n",
      "Loss: 0.389025, Train accuracy: 0.964556, val accuracy: 0.754000\n",
      "Loss: 0.715100, Train accuracy: 0.842333, val accuracy: 0.697000\n",
      "Loss: 0.870919, Train accuracy: 0.810222, val accuracy: 0.640000\n",
      "Loss: 0.373536, Train accuracy: 0.964556, val accuracy: 0.750000\n",
      "Loss: 0.489158, Train accuracy: 0.930667, val accuracy: 0.732000\n",
      "Loss: 0.641920, Train accuracy: 0.913556, val accuracy: 0.718000\n",
      "Loss: 0.483911, Train accuracy: 0.924000, val accuracy: 0.730000\n",
      "Loss: 0.646658, Train accuracy: 0.885000, val accuracy: 0.700000\n",
      "Loss: 0.604731, Train accuracy: 0.940333, val accuracy: 0.737000\n",
      "Loss: 0.484089, Train accuracy: 0.954333, val accuracy: 0.736000\n",
      "Loss: 0.399586, Train accuracy: 0.969000, val accuracy: 0.752000\n",
      "Loss: 0.540545, Train accuracy: 0.920778, val accuracy: 0.722000\n",
      "Loss: 0.456562, Train accuracy: 0.945889, val accuracy: 0.757000\n",
      "Loss: 0.585689, Train accuracy: 0.924778, val accuracy: 0.724000\n",
      "Loss: 0.393032, Train accuracy: 0.963222, val accuracy: 0.751000\n",
      "Loss: 0.433038, Train accuracy: 0.946889, val accuracy: 0.733000\n",
      "Loss: 0.387445, Train accuracy: 0.966333, val accuracy: 0.767000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.728718, Train accuracy: 0.870222, val accuracy: 0.680000\n",
      "Loss: 0.623356, Train accuracy: 0.897778, val accuracy: 0.703000\n",
      "Loss: 0.452421, Train accuracy: 0.941222, val accuracy: 0.745000\n",
      "Loss: 0.458801, Train accuracy: 0.958000, val accuracy: 0.747000\n",
      "Loss: 0.531434, Train accuracy: 0.935333, val accuracy: 0.748000\n",
      "Loss: 0.494627, Train accuracy: 0.865333, val accuracy: 0.677000\n",
      "Loss: 1.754650, Train accuracy: 0.690222, val accuracy: 0.575000\n",
      "Loss: 1.825477, Train accuracy: 0.665889, val accuracy: 0.564000\n",
      "Loss: 0.634615, Train accuracy: 0.822222, val accuracy: 0.662000\n",
      "Loss: 0.335931, Train accuracy: 0.950556, val accuracy: 0.740000\n",
      "Loss: 0.498585, Train accuracy: 0.951667, val accuracy: 0.746000\n",
      "Loss: 1.064778, Train accuracy: 0.829889, val accuracy: 0.672000\n",
      "Loss: 0.480495, Train accuracy: 0.918778, val accuracy: 0.721000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-d1bef2da3159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mbest_val_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/dl_course/assignments/assignment2/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;31m# use model to generate loss and gradients for all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# the params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/dl_course/assignments/assignment2/model.py\u001b[0m in \u001b[0;36mcompute_loss_and_gradients\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mbout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# After that, implement l2 regularization on all params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/dl_course/assignments/assignment2/layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, d_out)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0md_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0md_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [5e-1]#[5e-2, 1e-2, 5e-3, 2e-3]\n",
    "reg_strength = [1e-4]#,1e-4, 1e-5]\n",
    "learning_rate_decay = 0.997\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "momentum = [0.8]#,0.85,0.9,0.95]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "for lr in learning_rates:\n",
    "    for reg in reg_strength:\n",
    "        for mom in momentum:\n",
    "            model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hidden_layer_size, reg = reg)\n",
    "            dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "            trainer = Trainer(model, dataset, SGD(), learning_rate=lr, num_epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "            loss_history, train_history, val_history = trainer.fit()\n",
    "            if val_history[-1] > best_val_accuracy:\n",
    "                best_val_accuracy = val_history[-1]\n",
    "                best_classifier = model\n",
    "                print(lr, reg, mom, best_val_accuracy)\n",
    "    \n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f11ae414e80>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.146000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
