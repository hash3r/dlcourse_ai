{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "# assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "# assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradients are different at (0, 0). Analytic: -0.00001, Numeric: -0.00001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradients are different at (0, 0). Analytic: -0.01697, Numeric: -0.00849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666663"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.835925, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 2.323383, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 4.326708, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 5.236132, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 2.960961, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 2.735820, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 5.077341, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 4.599558, Train accuracy: 0.096778, val accuracy: 0.095000\n",
      "Loss: 2.401359, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 3.540366, Train accuracy: 0.093889, val accuracy: 0.090000\n",
      "Loss: 5.396065, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 3.697876, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 2.354999, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 4.456866, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 5.165339, Train accuracy: 0.093333, val accuracy: 0.090000\n",
      "Loss: 2.852649, Train accuracy: 0.096889, val accuracy: 0.094000\n",
      "Loss: 2.840220, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 5.154465, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 4.472172, Train accuracy: 0.093111, val accuracy: 0.090000\n",
      "Loss: 2.363762, Train accuracy: 0.093111, val accuracy: 0.090000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD())\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down and train and val accuracy go up for every epoch\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fafe50e4b70>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **40%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = 1e-4\n",
    "reg_strength = 1e-3\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = 128\n",
    "num_epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
